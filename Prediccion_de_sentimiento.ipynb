{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqNjlGkvOF32AzvJljXxlv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrithneyHernandez25/BrithneyHernandez.github.io/blob/main/Prediccion_de_sentimiento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2MzAwJb0gQV",
        "outputId": "cba41143-1155-4b8a-9821-d264e0e98aba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documento ID: 1noPa-dmGgXcBcoJx-mEsEZRY0ub7H0kdeMkqx2oaNDo\n",
            "                                            Headline Sentiment\n",
            "0  These are the streaming releases for January 2023     Mixto\n",
            "1              Top Amazon Prime Video series in 2022     Mixto\n",
            "2                       Series that return this 2022     Mixto\n",
            "3  Where to watch Barack Obama's favorite movies ...     Mixto\n",
            "4                                    Travel to a set     Mixto\n",
            "['Mixto' 'Positive' 'Negative' '']\n",
            "[0 2 1]\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 50, 128)           640000    \n",
            "                                                                 \n",
            " spatial_dropout1d (Spatial  (None, 50, 128)           0         \n",
            " Dropout1D)                                                      \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               91600     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 303       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 731903 (2.79 MB)\n",
            "Trainable params: 731903 (2.79 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "230/230 [==============================] - 45s 181ms/step - loss: 0.1576 - accuracy: 0.9713 - val_loss: 0.0943 - val_accuracy: 0.9804\n",
            "Epoch 2/5\n",
            "230/230 [==============================] - 41s 177ms/step - loss: 0.0754 - accuracy: 0.9829 - val_loss: 0.0772 - val_accuracy: 0.9839\n",
            "Epoch 3/5\n",
            "230/230 [==============================] - 43s 188ms/step - loss: 0.0513 - accuracy: 0.9869 - val_loss: 0.0738 - val_accuracy: 0.9847\n",
            "Epoch 4/5\n",
            "230/230 [==============================] - 40s 175ms/step - loss: 0.0369 - accuracy: 0.9894 - val_loss: 0.0781 - val_accuracy: 0.9865\n",
            "Epoch 5/5\n",
            "230/230 [==============================] - 42s 185ms/step - loss: 0.0303 - accuracy: 0.9914 - val_loss: 0.0809 - val_accuracy: 0.9845\n",
            "154/154 - 3s - loss: 0.0809 - accuracy: 0.9845 - 3s/epoch - 20ms/step\n",
            "Precisión en el conjunto de prueba: 0.98\n"
          ]
        }
      ],
      "source": [
        "# Autenticación e importación de bibliotecas necesarias\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import gspread\n",
        "import pandas as pd\n",
        "from google.auth import default\n",
        "from datetime import datetime\n",
        "\n",
        "# Autorización de credenciales\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# Definir la URL del archivo de Google Sheets\n",
        "url = \"https://docs.google.com/spreadsheets/d/1noPa-dmGgXcBcoJx-mEsEZRY0ub7H0kdeMkqx2oaNDo/edit#gid=0\"\n",
        "\n",
        "# Obtener el ID del documento\n",
        "doc_id = url.split(\"/\")[5]\n",
        "print(\"Documento ID:\", doc_id)\n",
        "\n",
        "# Abrir el documento y seleccionar la hoja de trabajo\n",
        "doc = gc.open_by_key(doc_id)\n",
        "ws = doc.worksheet(\"Sentimiento\")\n",
        "\n",
        "# Obtener todos los valores de la hoja\n",
        "values = ws.get_all_values()\n",
        "\n",
        "# Crear un DataFrame a partir de los valores, usando la segunda fila como encabezados\n",
        "df = pd.DataFrame(values[2:], columns=values[1])\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Verificar si las columnas 'Headline' y 'Sentiment' existen en el DataFrame\n",
        "columnas_requeridas = [\"Headline\", \"Sentiment\"]\n",
        "for col in columnas_requeridas:\n",
        "    if col not in df.columns:\n",
        "        raise ValueError(f\"La columna requerida '{col}' no está presente en el DataFrame\")\n",
        "\n",
        "# Filtrar el DataFrame para mantener solo las columnas necesarias\n",
        "df = df[columnas_requeridas]\n",
        "\n",
        "# Mostrar los primeros datos del DataFrame para verificación\n",
        "print(df.head())\n",
        "\n",
        "# Verificar los valores únicos en la columna 'Sentiment'\n",
        "print(df['Sentiment'].unique())\n",
        "\n",
        "# Eliminar filas con sentimientos vacíos\n",
        "df = df[df['Sentiment'].isin(['Positive', 'Negative', 'Mixto'])]\n",
        "\n",
        "# Codificar las etiquetas de sentimiento\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df['Sentiment'] = label_encoder.fit_transform(df['Sentiment'])\n",
        "\n",
        "# Verificar la codificación de los sentimientos\n",
        "print(df['Sentiment'].unique())\n",
        "\n",
        "# Codificar a categorías\n",
        "sentimientos_categoricos = to_categorical(df['Sentiment'], num_classes=3)\n",
        "\n",
        "# Convertir los encabezados a una lista de cadenas\n",
        "encabezados = df['Headline'].tolist()\n",
        "\n",
        "# Tokenizar y secuenciar los encabezados\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(encabezados)\n",
        "sequences = tokenizer.texts_to_sequences(encabezados)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=50)\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba (75% entrenamiento, 25% prueba)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, sentimientos_categoricos, test_size=0.25, random_state=42)\n",
        "\n",
        "# Definir la arquitectura del modelo\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, SpatialDropout1D\n",
        "\n",
        "modelo = Sequential()\n",
        "modelo.add(Embedding(input_dim=5000, output_dim=128, input_length=50))\n",
        "modelo.add(SpatialDropout1D(0.2))\n",
        "modelo.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "modelo.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compilar el modelo\n",
        "modelo.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Mostrar resumen del modelo\n",
        "modelo.summary()\n",
        "\n",
        "# Entrenar el modelo\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "epocas = 5\n",
        "tamano_lote = 64\n",
        "\n",
        "historia = modelo.fit(X_train, y_train, epochs=epocas, batch_size=tamano_lote, validation_data=(X_test, y_test), callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
        "\n",
        "# Evaluar el modelo\n",
        "perdida, precision = modelo.evaluate(X_test, y_test, verbose=2)\n",
        "print(f'Precisión en el conjunto de prueba: {precision:.2f}')\n",
        "\n",
        "# Función para predecir el sentimiento de nuevos encabezados\n",
        "def predecir_sentimiento(nuevo_encabezado):\n",
        "    secuencia = tokenizer.texts_to_sequences([nuevo_encabezado])\n",
        "    secuencia_padded = pad_sequences(secuencia, maxlen=50)\n",
        "    prediccion = modelo.predict(secuencia_padded)\n",
        "    clase_predicha = prediccion.argmax(axis=-1)[0]\n",
        "    sentimiento = label_encoder.inverse_transform([clase_predicha])[0]\n",
        "    return sentimiento\n",
        "\n",
        "\n"
      ]
    }
  ]
}